{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733537aa",
   "metadata": {
    "papermill": {
     "duration": 0.006687,
     "end_time": "2023-07-05T16:29:40.467172",
     "exception": false,
     "start_time": "2023-07-05T16:29:40.460485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Attempting to do machine translation following the [original seq2seq paper](https://paperswithcode.com/method/seq2seq). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0a60d",
   "metadata": {
    "papermill": {
     "duration": 0.005845,
     "end_time": "2023-07-05T16:29:40.479336",
     "exception": false,
     "start_time": "2023-07-05T16:29:40.473491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I will solve this problem in two parts.\n",
    "\n",
    " Part 1  : Converting the sentences into sequences. This will include removing NaN values, basic pre-processing (removing punctuation, converting to lower-case), tokenization and vocabulary creation.\n",
    "\n",
    "Part 2 : Building and training the seq2seq model, following the [paper](https://paperswithcode.com/method/seq2seq) closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763ffe9",
   "metadata": {
    "papermill": {
     "duration": 0.005739,
     "end_time": "2023-07-05T16:29:40.491135",
     "exception": false,
     "start_time": "2023-07-05T16:29:40.485396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Part 1 : Converting to sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e206c9",
   "metadata": {
    "papermill": {
     "duration": 0.005691,
     "end_time": "2023-07-05T16:29:40.502876",
     "exception": false,
     "start_time": "2023-07-05T16:29:40.497185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Removing Nan Values, Converting to lower case and removing punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35346cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:40.517338Z",
     "iopub.status.busy": "2023-07-05T16:29:40.516514Z",
     "iopub.status.idle": "2023-07-05T16:29:49.900553Z",
     "shell.execute_reply": "2023-07-05T16:29:49.899093Z"
    },
    "papermill": {
     "duration": 9.39567,
     "end_time": "2023-07-05T16:29:49.904607",
     "exception": false,
     "start_time": "2023-07-05T16:29:40.508937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए वह करन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>id like to tell you about one such child</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>this percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that theyre bad at not ...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>the ending portion of these vedas is called up...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127602</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>examples of art deco construction can be found...</td>\n",
       "      <td>आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127603</th>\n",
       "      <td>ted</td>\n",
       "      <td>and put it in our cheeks</td>\n",
       "      <td>और अपने गालों में डाल लेते हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127604</th>\n",
       "      <td>tides</td>\n",
       "      <td>as for the other derivatives of sulphur  the c...</td>\n",
       "      <td>जहां तक गंधक के अन्य उत्पादों का प्रश्न है  दे...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127605</th>\n",
       "      <td>tides</td>\n",
       "      <td>its complicated functioning is defined thus in...</td>\n",
       "      <td>Zरचनाप्रकिया को उसने एक पहेली में यों बांधा है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127606</th>\n",
       "      <td>ted</td>\n",
       "      <td>theyve just won four government contracts to b...</td>\n",
       "      <td>हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127605 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "0             ted  politicians do not have permission to do what ...   \n",
       "1             ted           id like to tell you about one such child   \n",
       "2       indic2012  this percentage is even greater than the perce...   \n",
       "3             ted  what we really mean is that theyre bad at not ...   \n",
       "4       indic2012  the ending portion of these vedas is called up...   \n",
       "...           ...                                                ...   \n",
       "127602  indic2012  examples of art deco construction can be found...   \n",
       "127603        ted                           and put it in our cheeks   \n",
       "127604      tides  as for the other derivatives of sulphur  the c...   \n",
       "127605      tides  its complicated functioning is defined thus in...   \n",
       "127606        ted  theyve just won four government contracts to b...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "0       राजनीतिज्ञों के पास जो कार्य करना चाहिए वह करन...  \n",
       "1       मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी  \n",
       "2        यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3          हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4             इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
       "...                                                   ...  \n",
       "127602  आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...  \n",
       "127603                    और अपने गालों में डाल लेते हैं।  \n",
       "127604  जहां तक गंधक के अन्य उत्पादों का प्रश्न है  दे...  \n",
       "127605    Zरचनाप्रकिया को उसने एक पहेली में यों बांधा है   \n",
       "127606  हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...  \n",
       "\n",
       "[127605 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/english-hindi-machine-translation/Hindi_English_Truncated_Corpus.csv')\n",
    "\n",
    "df = df.dropna()  # Remove NaN values\n",
    "\n",
    "# Converting English sentences to lowercase and removing punctuations from both languages\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['english_sentence'] = df['english_sentence'].str.lower().apply(remove_punctuation)\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(remove_punctuation)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e417f5",
   "metadata": {
    "papermill": {
     "duration": 0.008056,
     "end_time": "2023-07-05T16:29:49.919744",
     "exception": false,
     "start_time": "2023-07-05T16:29:49.911688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before tokenizing or creating vocabularies split the data into train, validation and test. This prevents \"information leakage\" into the test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807959e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:49.934879Z",
     "iopub.status.busy": "2023-07-05T16:29:49.934154Z",
     "iopub.status.idle": "2023-07-05T16:29:49.992061Z",
     "shell.execute_reply": "2023-07-05T16:29:49.990826Z"
    },
    "papermill": {
     "duration": 0.068606,
     "end_time": "2023-07-05T16:29:49.994872",
     "exception": false,
     "start_time": "2023-07-05T16:29:49.926266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e108643c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:50.010511Z",
     "iopub.status.busy": "2023-07-05T16:29:50.009446Z",
     "iopub.status.idle": "2023-07-05T16:29:50.165353Z",
     "shell.execute_reply": "2023-07-05T16:29:50.164040Z"
    },
    "papermill": {
     "duration": 0.16678,
     "end_time": "2023-07-05T16:29:50.168211",
     "exception": false,
     "start_time": "2023-07-05T16:29:50.001431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(source              102084\n",
       " english_sentence    102084\n",
       " hindi_sentence      102084\n",
       " dtype: int64,\n",
       " source              12760\n",
       " english_sentence    12760\n",
       " hindi_sentence      12760\n",
       " dtype: int64,\n",
       " source              12761\n",
       " english_sentence    12761\n",
       " hindi_sentence      12761\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count(),val_df.count(),test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8bd32",
   "metadata": {
    "papermill": {
     "duration": 0.006513,
     "end_time": "2023-07-05T16:29:50.181778",
     "exception": false,
     "start_time": "2023-07-05T16:29:50.175265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tokenizing the sentences. Source sentences are tokenized in reverse as it was one of the key source of improvement in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d82f4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:50.200220Z",
     "iopub.status.busy": "2023-07-05T16:29:50.199039Z",
     "iopub.status.idle": "2023-07-05T16:29:51.607074Z",
     "shell.execute_reply": "2023-07-05T16:29:51.605883Z"
    },
    "papermill": {
     "duration": 1.419085,
     "end_time": "2023-07-05T16:29:51.609780",
     "exception": false,
     "start_time": "2023-07-05T16:29:50.190695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82661</th>\n",
       "      <td>tides</td>\n",
       "      <td>[SOS, unions, trade, strong, of, up, building,...</td>\n",
       "      <td>[SOS, इसलिए, मजदूर, वर्ग, की, पहली, जरूरत, यह,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121426</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>[SOS, 1830, of, decade, the, during, marble, i...</td>\n",
       "      <td>[SOS, इस, तथ्य, के, भी, कोई, साक्ष्य, नहीं, है...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30572</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>[SOS, pradesh, uttar, in, districts, 70, are, ...</td>\n",
       "      <td>[SOS, उत्तर, प्रदेश, में, ७०, जिले, हैं, EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25371</th>\n",
       "      <td>ted</td>\n",
       "      <td>[SOS, schoolhouse, the, to, way, the, on, scho...</td>\n",
       "      <td>[SOS, या, तो, स्कूल, में, या, स्कूल, आतेजाते, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56266</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>[SOS, road, northsouth, long, the, crosses, it...</td>\n",
       "      <td>[SOS, इसके, बाद, एक, बडा़, खुला, स्थान, है, जह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19147</th>\n",
       "      <td>tides</td>\n",
       "      <td>[SOS, control, to, difficult, more, seem, pku,...</td>\n",
       "      <td>[SOS, फ्खू, जैस, उत्परिवर्तन, पर, नियंत्रण, पा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26135</th>\n",
       "      <td>ted</td>\n",
       "      <td>[SOS, dollars, 5000, around, costing, was, tim...</td>\n",
       "      <td>[SOS, उस, समय, 5000, डालर, की, थी, EOS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77079</th>\n",
       "      <td>tides</td>\n",
       "      <td>[SOS, them, harmonise, to, attempt, an, make, ...</td>\n",
       "      <td>[SOS, दार्शनिक, और, इतिहास, उनमें, से, एक, या,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39591</th>\n",
       "      <td>tides</td>\n",
       "      <td>[SOS, 4344, pages, see, order, on, goods, of, ...</td>\n",
       "      <td>[SOS, डिपाजऋटि, के, बारे, में, जऋऊण्श्छ्ष्यादा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14882</th>\n",
       "      <td>tides</td>\n",
       "      <td>[SOS, it, of, amount, some, needs, badly, subc...</td>\n",
       "      <td>[SOS, यह, सच, है, कि, वाजपेयी, ने, एक, पक्के, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "82661       tides  [SOS, unions, trade, strong, of, up, building,...   \n",
       "121426  indic2012  [SOS, 1830, of, decade, the, during, marble, i...   \n",
       "30572   indic2012  [SOS, pradesh, uttar, in, districts, 70, are, ...   \n",
       "25371         ted  [SOS, schoolhouse, the, to, way, the, on, scho...   \n",
       "56266   indic2012  [SOS, road, northsouth, long, the, crosses, it...   \n",
       "19147       tides  [SOS, control, to, difficult, more, seem, pku,...   \n",
       "26135         ted  [SOS, dollars, 5000, around, costing, was, tim...   \n",
       "77079       tides  [SOS, them, harmonise, to, attempt, an, make, ...   \n",
       "39591       tides  [SOS, 4344, pages, see, order, on, goods, of, ...   \n",
       "14882       tides  [SOS, it, of, amount, some, needs, badly, subc...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "82661   [SOS, इसलिए, मजदूर, वर्ग, की, पहली, जरूरत, यह,...  \n",
       "121426  [SOS, इस, तथ्य, के, भी, कोई, साक्ष्य, नहीं, है...  \n",
       "30572       [SOS, उत्तर, प्रदेश, में, ७०, जिले, हैं, EOS]  \n",
       "25371   [SOS, या, तो, स्कूल, में, या, स्कूल, आतेजाते, ...  \n",
       "56266   [SOS, इसके, बाद, एक, बडा़, खुला, स्थान, है, जह...  \n",
       "19147   [SOS, फ्खू, जैस, उत्परिवर्तन, पर, नियंत्रण, पा...  \n",
       "26135             [SOS, उस, समय, 5000, डालर, की, थी, EOS]  \n",
       "77079   [SOS, दार्शनिक, और, इतिहास, उनमें, से, एक, या,...  \n",
       "39591   [SOS, डिपाजऋटि, के, बारे, में, जऋऊण्श्छ्ष्यादा...  \n",
       "14882   [SOS, यह, सच, है, कि, वाजपेयी, ने, एक, पक्के, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tokens\n",
    "START_TOKEN = 'SOS'\n",
    "END_TOKEN = 'EOS'\n",
    "OUT_OF_VOCAB_TOKEN = 'OOV'\n",
    "\n",
    "\n",
    "# Tokenize the sentences and add EOS and SOS tokens\n",
    "train_df['english_sentence'] = train_df['english_sentence'].apply(lambda x: [START_TOKEN] + x.split()[::-1] + [END_TOKEN])\n",
    "train_df['hindi_sentence'] = train_df['hindi_sentence'].apply(lambda x: [START_TOKEN] + x.split() + [END_TOKEN])\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad46813",
   "metadata": {
    "papermill": {
     "duration": 0.006743,
     "end_time": "2023-07-05T16:29:51.623642",
     "exception": false,
     "start_time": "2023-07-05T16:29:51.616899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating the frequency counter , words having frequency =1 will not be included in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b39e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:51.639968Z",
     "iopub.status.busy": "2023-07-05T16:29:51.639524Z",
     "iopub.status.idle": "2023-07-05T16:29:52.646051Z",
     "shell.execute_reply": "2023-07-05T16:29:52.644923Z"
    },
    "papermill": {
     "duration": 1.018083,
     "end_time": "2023-07-05T16:29:52.648741",
     "exception": false,
     "start_time": "2023-07-05T16:29:51.630658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('the', 103848),\n",
       "  ('SOS', 102084),\n",
       "  ('EOS', 102084),\n",
       "  ('of', 59641),\n",
       "  ('and', 47380),\n",
       "  ('to', 38179),\n",
       "  ('in', 37816),\n",
       "  ('a', 29128),\n",
       "  ('is', 23864),\n",
       "  ('that', 14843)],\n",
       " [('SOS', 102084),\n",
       "  ('EOS', 102084),\n",
       "  ('के', 70335),\n",
       "  ('में', 51408),\n",
       "  ('है', 45851),\n",
       "  ('की', 39470),\n",
       "  ('और', 38008),\n",
       "  ('से', 30831),\n",
       "  ('का', 26611),\n",
       "  ('को', 25161)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define minimum word frequency for it to be included in vocabulary\n",
    "MIN_WORD_FREQ = 2\n",
    "\n",
    "# Count the frequency of each word in both languages\n",
    "english_vocab_counter = Counter(word for sentence in train_df['english_sentence'] for word in sentence)\n",
    "hindi_vocab_counter = Counter(word for sentence in train_df['hindi_sentence'] for word in sentence)\n",
    "\n",
    "english_vocab_counter.most_common(10) ,hindi_vocab_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a78b97",
   "metadata": {
    "papermill": {
     "duration": 0.006863,
     "end_time": "2023-07-05T16:29:52.662936",
     "exception": false,
     "start_time": "2023-07-05T16:29:52.656073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating the vocabulary and adding the 'OOV' token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cb08b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:52.679269Z",
     "iopub.status.busy": "2023-07-05T16:29:52.678829Z",
     "iopub.status.idle": "2023-07-05T16:29:52.740284Z",
     "shell.execute_reply": "2023-07-05T16:29:52.739191Z"
    },
    "papermill": {
     "duration": 0.07313,
     "end_time": "2023-07-05T16:29:52.743183",
     "exception": false,
     "start_time": "2023-07-05T16:29:52.670053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create vocabulary by including words that have a frequency of more than MIN_WORD_FREQ\n",
    "english_vocab = {word: i for i, (word, freq) in enumerate(english_vocab_counter.items()) if freq >= MIN_WORD_FREQ}\n",
    "hindi_vocab = {word: i for i, (word, freq) in enumerate(hindi_vocab_counter.items()) if freq >= MIN_WORD_FREQ}\n",
    "# OOV token will be displayed when we encounter a word not in the vocabulary\n",
    "english_vocab.update({OUT_OF_VOCAB_TOKEN: len(english_vocab)})\n",
    "hindi_vocab.update({OUT_OF_VOCAB_TOKEN: len(hindi_vocab)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734501d7",
   "metadata": {
    "papermill": {
     "duration": 0.006902,
     "end_time": "2023-07-05T16:29:52.757411",
     "exception": false,
     "start_time": "2023-07-05T16:29:52.750509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, converting sentences to sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4640a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:52.773419Z",
     "iopub.status.busy": "2023-07-05T16:29:52.773002Z",
     "iopub.status.idle": "2023-07-05T16:29:54.585777Z",
     "shell.execute_reply": "2023-07-05T16:29:54.584609Z"
    },
    "papermill": {
     "duration": 1.823891,
     "end_time": "2023-07-05T16:29:54.588431",
     "exception": false,
     "start_time": "2023-07-05T16:29:52.764540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82661     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 41227, ...\n",
       "121426    [0, 28, 29, 30, 31, 32, 33, 34, 16, 9, 35, 36,...\n",
       "30572                       [0, 55, 56, 24, 57, 58, 16, 27]\n",
       "25371                   [0, 59, 60, 61, 24, 59, 61, 62, 27]\n",
       "56266     [0, 63, 64, 10, 65, 66, 67, 8, 68, 7, 69, 70, ...\n",
       "19147            [0, 74, 75, 76, 77, 78, 79, 80, 81, 8, 27]\n",
       "26135                        [0, 82, 83, 84, 85, 4, 86, 27]\n",
       "77079     [0, 87, 88, 89, 90, 91, 10, 59, 92, 30, 93, 94...\n",
       "39591     [0, 41227, 30, 104, 24, 105, 106, 30, 107, 108...\n",
       "14882     [0, 7, 119, 8, 9, 120, 41, 10, 121, 122, 4, 12...\n",
       "44539     [0, 131, 30, 132, 4, 133, 134, 24, 135, 41227,...\n",
       "77431                           [0, 169, 170, 171, 172, 27]\n",
       "84191                       [0, 173, 174, 34, 175, 176, 27]\n",
       "71777                                [0, 177, 178, 179, 27]\n",
       "92433     [0, 180, 181, 127, 182, 183, 8, 184, 185, 186,...\n",
       "77639     [0, 193, 194, 64, 195, 196, 197, 41, 198, 77, ...\n",
       "28978                                          [0, 205, 27]\n",
       "36665     [0, 206, 207, 208, 209, 45, 210, 77, 211, 212,...\n",
       "98741                   [0, 19, 223, 224, 225, 226, 16, 27]\n",
       "99709             [0, 227, 228, 229, 230, 142, 231, 73, 27]\n",
       "Name: hindi_sentence, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the words in the sentences to their corresponding index in the vocabulary\n",
    "train_df['english_sentence'] = train_df['english_sentence'].apply(lambda sentence: [english_vocab.get(word, english_vocab[OUT_OF_VOCAB_TOKEN]) for word in sentence])\n",
    "train_df['hindi_sentence'] = train_df['hindi_sentence'].apply(lambda sentence: [hindi_vocab.get(word, hindi_vocab[OUT_OF_VOCAB_TOKEN]) for word in sentence])\n",
    "train_df['hindi_sentence'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce8aea98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:54.605566Z",
     "iopub.status.busy": "2023-07-05T16:29:54.604930Z",
     "iopub.status.idle": "2023-07-05T16:29:54.618870Z",
     "shell.execute_reply": "2023-07-05T16:29:54.617763Z"
    },
    "papermill": {
     "duration": 0.025358,
     "end_time": "2023-07-05T16:29:54.621239",
     "exception": false,
     "start_time": "2023-07-05T16:29:54.595881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82661     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 41227, ...\n",
       "121426    [0, 28, 29, 30, 31, 32, 33, 34, 16, 9, 35, 36,...\n",
       "30572                       [0, 55, 56, 24, 57, 58, 16, 27]\n",
       "25371                   [0, 59, 60, 61, 24, 59, 61, 62, 27]\n",
       "56266     [0, 63, 64, 10, 65, 66, 67, 8, 68, 7, 69, 70, ...\n",
       "19147            [0, 74, 75, 76, 77, 78, 79, 80, 81, 8, 27]\n",
       "26135                        [0, 82, 83, 84, 85, 4, 86, 27]\n",
       "77079     [0, 87, 88, 89, 90, 91, 10, 59, 92, 30, 93, 94...\n",
       "39591     [0, 41227, 30, 104, 24, 105, 106, 30, 107, 108...\n",
       "14882     [0, 7, 119, 8, 9, 120, 41, 10, 121, 122, 4, 12...\n",
       "44539     [0, 131, 30, 132, 4, 133, 134, 24, 135, 41227,...\n",
       "77431                           [0, 169, 170, 171, 172, 27]\n",
       "84191                       [0, 173, 174, 34, 175, 176, 27]\n",
       "71777                                [0, 177, 178, 179, 27]\n",
       "92433     [0, 180, 181, 127, 182, 183, 8, 184, 185, 186,...\n",
       "77639     [0, 193, 194, 64, 195, 196, 197, 41, 198, 77, ...\n",
       "28978                                          [0, 205, 27]\n",
       "36665     [0, 206, 207, 208, 209, 45, 210, 77, 211, 212,...\n",
       "98741                   [0, 19, 223, 224, 225, 226, 16, 27]\n",
       "99709             [0, 227, 228, 229, 230, 142, 231, 73, 27]\n",
       "Name: hindi_sentence, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['hindi_sentence'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b835d6",
   "metadata": {
    "papermill": {
     "duration": 0.007653,
     "end_time": "2023-07-05T16:29:54.636375",
     "exception": false,
     "start_time": "2023-07-05T16:29:54.628722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8479cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-05T16:29:54.654008Z",
     "iopub.status.busy": "2023-07-05T16:29:54.653363Z",
     "iopub.status.idle": "2023-07-05T16:29:54.662998Z",
     "shell.execute_reply": "2023-07-05T16:29:54.662047Z"
    },
    "papermill": {
     "duration": 0.021443,
     "end_time": "2023-07-05T16:29:54.665563",
     "exception": false,
     "start_time": "2023-07-05T16:29:54.644120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a PyTorch Dataset\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.df.iloc[idx]['english_sentence']), torch.tensor(self.df.iloc[idx]['hindi_sentence'])\n",
    "\n",
    "# Define a function to create data loaders\n",
    "def create_data_loaders(train_df, val_df, test_df, batch_size=32):\n",
    "    train_loader = DataLoader(TranslationDataset(train_df), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TranslationDataset(val_df), batch_size=batch_size)\n",
    "    test_loader = DataLoader(TranslationDataset(test_df), batch_size=batch_size)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(train_df, val_df, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393307b",
   "metadata": {
    "papermill": {
     "duration": 0.007872,
     "end_time": "2023-07-05T16:29:54.681091",
     "exception": false,
     "start_time": "2023-07-05T16:29:54.673219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### This marks the end of the data preparation now we will define the seq2seq model and train it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.171033,
   "end_time": "2023-07-05T16:29:56.615280",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-05T16:29:27.444247",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

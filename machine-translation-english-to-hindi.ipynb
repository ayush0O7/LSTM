{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d88a280",
   "metadata": {
    "papermill": {
     "duration": 0.009872,
     "end_time": "2023-07-13T06:40:52.635277",
     "exception": false,
     "start_time": "2023-07-13T06:40:52.625405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Attempting to do machine translation following the [original seq2seq paper](https://paperswithcode.com/method/seq2seq). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d08cf",
   "metadata": {
    "papermill": {
     "duration": 0.009062,
     "end_time": "2023-07-13T06:40:52.654448",
     "exception": false,
     "start_time": "2023-07-13T06:40:52.645386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I will solve this problem in two parts.\n",
    "\n",
    " Part 1  : Converting the sentences into sequences. This will include removing NaN values, basic pre-processing (removing punctuation, converting to lower-case), tokenization and vocabulary creation.\n",
    "\n",
    "Part 2 : Building and training the seq2seq model, following the [paper](https://paperswithcode.com/method/seq2seq) closely(relation between input-output of encoder-decoder,number of layers in LSTM etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63fc178",
   "metadata": {
    "papermill": {
     "duration": 0.008833,
     "end_time": "2023-07-13T06:40:52.672432",
     "exception": false,
     "start_time": "2023-07-13T06:40:52.663599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Part 1 : Converting to sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0c00c",
   "metadata": {
    "papermill": {
     "duration": 0.009013,
     "end_time": "2023-07-13T06:40:52.690512",
     "exception": false,
     "start_time": "2023-07-13T06:40:52.681499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Removing Nan Values, Converting to lower case and removing punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa27c9b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:40:52.710414Z",
     "iopub.status.busy": "2023-07-13T06:40:52.709931Z",
     "iopub.status.idle": "2023-07-13T06:41:00.634062Z",
     "shell.execute_reply": "2023-07-13T06:41:00.633133Z"
    },
    "papermill": {
     "duration": 7.936841,
     "end_time": "2023-07-13T06:41:00.636399",
     "exception": false,
     "start_time": "2023-07-13T06:40:52.699558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए वह करन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>id like to tell you about one such child</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>this percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that theyre bad at not ...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>the ending portion of these vedas is called up...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127602</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>examples of art deco construction can be found...</td>\n",
       "      <td>आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127603</th>\n",
       "      <td>ted</td>\n",
       "      <td>and put it in our cheeks</td>\n",
       "      <td>और अपने गालों में डाल लेते हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127604</th>\n",
       "      <td>tides</td>\n",
       "      <td>as for the other derivatives of sulphur  the c...</td>\n",
       "      <td>जहां तक गंधक के अन्य उत्पादों का प्रश्न है  दे...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127605</th>\n",
       "      <td>tides</td>\n",
       "      <td>its complicated functioning is defined thus in...</td>\n",
       "      <td>Zरचनाप्रकिया को उसने एक पहेली में यों बांधा है</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127606</th>\n",
       "      <td>ted</td>\n",
       "      <td>theyve just won four government contracts to b...</td>\n",
       "      <td>हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127605 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "0             ted  politicians do not have permission to do what ...   \n",
       "1             ted           id like to tell you about one such child   \n",
       "2       indic2012  this percentage is even greater than the perce...   \n",
       "3             ted  what we really mean is that theyre bad at not ...   \n",
       "4       indic2012  the ending portion of these vedas is called up...   \n",
       "...           ...                                                ...   \n",
       "127602  indic2012  examples of art deco construction can be found...   \n",
       "127603        ted                           and put it in our cheeks   \n",
       "127604      tides  as for the other derivatives of sulphur  the c...   \n",
       "127605      tides  its complicated functioning is defined thus in...   \n",
       "127606        ted  theyve just won four government contracts to b...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "0       राजनीतिज्ञों के पास जो कार्य करना चाहिए वह करन...  \n",
       "1       मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी  \n",
       "2        यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3          हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4             इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
       "...                                                   ...  \n",
       "127602  आर्ट डेको शैली के निर्माण मैरीन ड्राइव और ओवल ...  \n",
       "127603                    और अपने गालों में डाल लेते हैं।  \n",
       "127604  जहां तक गंधक के अन्य उत्पादों का प्रश्न है  दे...  \n",
       "127605    Zरचनाप्रकिया को उसने एक पहेली में यों बांधा है   \n",
       "127606  हाल ही में उन्हें सरकारी ठेका मिला है करीब सौ ...  \n",
       "\n",
       "[127605 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/english-hindi-machine-translation/Hindi_English_Truncated_Corpus.csv')\n",
    "\n",
    "df = df.dropna()  # Remove NaN values\n",
    "\n",
    "# Converting English sentences to lowercase and removing punctuations from both languages\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "df['english_sentence'] = df['english_sentence'].str.lower().apply(remove_punctuation)\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(remove_punctuation)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfcb1c0",
   "metadata": {
    "papermill": {
     "duration": 0.009351,
     "end_time": "2023-07-13T06:41:00.655953",
     "exception": false,
     "start_time": "2023-07-13T06:41:00.646602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Splitting the data into train, validation and test. Taking a small sample of the data because of limited compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a9d6a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:00.676916Z",
     "iopub.status.busy": "2023-07-13T06:41:00.676077Z",
     "iopub.status.idle": "2023-07-13T06:41:00.863111Z",
     "shell.execute_reply": "2023-07-13T06:41:00.862054Z"
    },
    "papermill": {
     "duration": 0.200385,
     "end_time": "2023-07-13T06:41:00.865786",
     "exception": false,
     "start_time": "2023-07-13T06:41:00.665401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(source              12760\n",
       " english_sentence    12760\n",
       " hindi_sentence      12760\n",
       " dtype: int64,\n",
       " source              11484\n",
       " english_sentence    11484\n",
       " hindi_sentence      11484\n",
       " dtype: int64,\n",
       " source              103361\n",
       " english_sentence    103361\n",
       " hindi_sentence      103361\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.9, random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.9, random_state=42)\n",
    "train_df.count(),val_df.count(),test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cc3fb",
   "metadata": {
    "papermill": {
     "duration": 0.009408,
     "end_time": "2023-07-13T06:41:00.885110",
     "exception": false,
     "start_time": "2023-07-13T06:41:00.875702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tokenizing the sentences. Source sentences are tokenized in reverse as it was one of the key source of improvement in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b22478f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:00.905569Z",
     "iopub.status.busy": "2023-07-13T06:41:00.905258Z",
     "iopub.status.idle": "2023-07-13T06:41:02.202356Z",
     "shell.execute_reply": "2023-07-13T06:41:02.201250Z"
    },
    "papermill": {
     "duration": 1.310935,
     "end_time": "2023-07-13T06:41:02.205661",
     "exception": false,
     "start_time": "2023-07-13T06:41:00.894726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           source                                   english_sentence  \\\n",
      "9425        tides  [EOS, incentives, other, and, currency, devalu...   \n",
      "93313         ted  [EOS, that, and, complete, are, triumphs, our,...   \n",
      "110779  indic2012  [EOS, malaria, cause, which, creatures, change...   \n",
      "106155  indic2012  [EOS, festival, film, international, toronto, ...   \n",
      "\n",
      "                                           hindi_sentence  \n",
      "9425    [SOS, प्राकृतिक, रूप, से, कम, कीमत, का, लाभ, ज...  \n",
      "93313   [SOS, अब, हमारी, विजय, पूरी, हो, चुकी, है, और,...  \n",
      "110779  [SOS, उष्णकटिबंधीय, बीमारियां, tropical, disea...  \n",
      "106155  [SOS, उनकी, पहली, अंग्रेजी, भाषा, की, फिल्म, र...  \n",
      "          source                                   english_sentence  \\\n",
      "59399      tides  [EOS, afghanistan, in, loyalties, changing, of...   \n",
      "17253      tides  [EOS, beginning, the, from, state, hidden, a, ...   \n",
      "99756        ted  [EOS, directions, different, into, growing, ar...   \n",
      "28652  indic2012  [EOS, sanadyataptilok, prasad, poetryghanshyam...   \n",
      "\n",
      "                                          hindi_sentence  \n",
      "59399  [SOS, इन, चर्चाओं, में, किसी, बड़ै, तालिबान, न...  \n",
      "17253  [SOS, अपनी, प्रारंभिक, गुप्त, अवस्था, से, चीजो...  \n",
      "99756        [SOS, अलग, दिशाओं, में, बड़, रहे, हैं, EOS]  \n",
      "28652  [SOS, पुष्टिकाव्य, की, दार्शनिक, पृष्ठभूमि, घन...  \n",
      "          source                                   english_sentence  \\\n",
      "15224        ted  [EOS, us, help, can, science, that, thought, i...   \n",
      "57682  indic2012  [EOS, agra, of, gaughat, near, lived, was, soo...   \n",
      "75234  indic2012  [EOS, situations, the, controlling, in, govt, ...   \n",
      "48380  indic2012  [EOS, year, one, to, time, this, reduce, to, h...   \n",
      "\n",
      "                                          hindi_sentence  \n",
      "15224  [SOS, माना, जाता, है, कि, विज्ञान, बस, हमारी, ...  \n",
      "57682  [SOS, प्रारंभ, में, सूरदास, आगरा, के, समीप, गऊ...  \n",
      "75234  [SOS, अखिल, भारतीय, सेवाएँ, भी, केन्द्र, को, र...  \n",
      "48380  [SOS, नेहरू, और, बोस, ने, मांग, की, कि, इस, सम...  \n"
     ]
    }
   ],
   "source": [
    "# Define tokens\n",
    "START_TOKEN = 'SOS'\n",
    "END_TOKEN = 'EOS'\n",
    "OUT_OF_VOCAB_TOKEN = 'OOV'\n",
    "\n",
    "def tokenize(df):\n",
    "    df['english_sentence'] = df['english_sentence'].apply(lambda x: [END_TOKEN] + x.split()[::-1] + [START_TOKEN])\n",
    "    df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: [START_TOKEN] + x.split() + [END_TOKEN])\n",
    "    print(df.head(4))\n",
    "\n",
    "# Tokenize the sentences and add EOS and SOS tokens\n",
    "#train_df['english_sentence'] = train_df['english_sentence'].apply(lambda x: [END_TOKEN] + x.split()[::-1] + [START_TOKEN])\n",
    "#train_df['hindi_sentence'] = train_df['hindi_sentence'].apply(lambda x: [START_TOKEN] + x.split() + [END_TOKEN])\n",
    "\n",
    "tokenize(train_df)\n",
    "tokenize(val_df)\n",
    "tokenize(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4bea6",
   "metadata": {
    "papermill": {
     "duration": 0.009688,
     "end_time": "2023-07-13T06:41:02.225925",
     "exception": false,
     "start_time": "2023-07-13T06:41:02.216237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Creating vocabulary(First counter then vocabulary) using only the training set since it prevents information leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96024025",
   "metadata": {
    "papermill": {
     "duration": 0.00943,
     "end_time": "2023-07-13T06:41:02.245682",
     "exception": false,
     "start_time": "2023-07-13T06:41:02.236252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating the frequency counter , words having frequency =1 will not be included in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d01ed2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:02.266477Z",
     "iopub.status.busy": "2023-07-13T06:41:02.266104Z",
     "iopub.status.idle": "2023-07-13T06:41:02.377333Z",
     "shell.execute_reply": "2023-07-13T06:41:02.376245Z"
    },
    "papermill": {
     "duration": 0.124311,
     "end_time": "2023-07-13T06:41:02.379739",
     "exception": false,
     "start_time": "2023-07-13T06:41:02.255428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('the', 12836),\n",
       "  ('EOS', 12760),\n",
       "  ('SOS', 12760),\n",
       "  ('of', 7374),\n",
       "  ('and', 5896),\n",
       "  ('to', 4807),\n",
       "  ('in', 4772),\n",
       "  ('a', 3660),\n",
       "  ('is', 3040),\n",
       "  ('that', 1760)],\n",
       " [('SOS', 12760),\n",
       "  ('EOS', 12760),\n",
       "  ('के', 8628),\n",
       "  ('में', 6486),\n",
       "  ('है', 5534),\n",
       "  ('की', 4877),\n",
       "  ('और', 4745),\n",
       "  ('से', 3881),\n",
       "  ('का', 3364),\n",
       "  ('को', 3158)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define minimum word frequency for it to be included in vocabulary\n",
    "MIN_WORD_FREQ = 2\n",
    "\n",
    "# Count the frequency of each word in both languages\n",
    "english_vocab_counter = Counter(word for sentence in train_df['english_sentence'] for word in sentence)\n",
    "hindi_vocab_counter = Counter(word for sentence in train_df['hindi_sentence'] for word in sentence)\n",
    "\n",
    "english_vocab_counter.most_common(10) ,hindi_vocab_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1995895c",
   "metadata": {
    "papermill": {
     "duration": 0.010179,
     "end_time": "2023-07-13T06:41:02.400294",
     "exception": false,
     "start_time": "2023-07-13T06:41:02.390115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating the dictionary using words only from the training set. Creating the vocabulary and adding the 'OOV' token. Doing word: i+1 to keep 0 for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f70779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:02.423335Z",
     "iopub.status.busy": "2023-07-13T06:41:02.422237Z",
     "iopub.status.idle": "2023-07-13T06:41:02.460011Z",
     "shell.execute_reply": "2023-07-13T06:41:02.459033Z"
    },
    "papermill": {
     "duration": 0.051205,
     "end_time": "2023-07-13T06:41:02.462084",
     "exception": false,
     "start_time": "2023-07-13T06:41:02.410879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9858, 11336, 11335, 9857)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary by including words that have a frequency of more than MIN_WORD_FREQ\n",
    "#english_vocab = {word: i+1 for i, (word, freq) in enumerate(english_vocab_counter.items()) if freq >= MIN_WORD_FREQ}\n",
    "#hindi_vocab = {word: i+1 for i, (word, freq) in enumerate(hindi_vocab_counter.items()) if freq >= MIN_WORD_FREQ}\n",
    "# OOV token will be displayed when we encounter a word not in the vocabulary\n",
    "i=1\n",
    "english_vocab={}\n",
    "english_index_to_word={}\n",
    "for _, (word, freq) in enumerate(english_vocab_counter.items()):\n",
    "    if freq >= MIN_WORD_FREQ and english_vocab.__contains__(word)==False:\n",
    "        english_vocab[word]=i\n",
    "        english_index_to_word[i]=word\n",
    "        i+=1\n",
    "\n",
    "i=1\n",
    "hindi_vocab={}\n",
    "hindi_index_to_word={}\n",
    "for _, (word, freq) in enumerate(hindi_vocab_counter.items()):\n",
    "    if freq >= MIN_WORD_FREQ and hindi_vocab.__contains__(word)==False:\n",
    "        hindi_vocab[word]=i\n",
    "        hindi_index_to_word[i]=word\n",
    "        i+=1\n",
    "english_vocab.update({OUT_OF_VOCAB_TOKEN: len(english_vocab)})\n",
    "hindi_vocab.update({OUT_OF_VOCAB_TOKEN: len(hindi_vocab)})\n",
    "len(english_vocab),len(hindi_vocab),len(hindi_index_to_word),len(english_index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497ac7c",
   "metadata": {
    "papermill": {
     "duration": 0.00976,
     "end_time": "2023-07-13T06:41:02.482047",
     "exception": false,
     "start_time": "2023-07-13T06:41:02.472287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, converting sentences to sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8740a79b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:02.503617Z",
     "iopub.status.busy": "2023-07-13T06:41:02.502831Z",
     "iopub.status.idle": "2023-07-13T06:41:04.551245Z",
     "shell.execute_reply": "2023-07-13T06:41:04.550141Z"
    },
    "papermill": {
     "duration": 2.061421,
     "end_time": "2023-07-13T06:41:04.553424",
     "exception": false,
     "start_time": "2023-07-13T06:41:02.492003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9425      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n",
      "93313           [1, 26, 27, 28, 29, 22, 30, 12, 16, 31, 25]\n",
      "110779    [1, 32, 33, 34, 35, 36, 37, 38, 39, 40, 38, 41...\n",
      "106155    [1, 55, 56, 57, 58, 59, 60, 11335, 61, 11335, ...\n",
      "68713     [1, 78, 79, 80, 12, 81, 82, 11335, 11335, 7, 8...\n",
      "Name: hindi_sentence, dtype: object 9425      [1, 2, 3, 4, 5, 9857, 6, 7, 8, 9, 10, 11, 12, ...\n",
      "93313                    [1, 18, 4, 19, 20, 21, 22, 18, 17]\n",
      "110779    [1, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33...\n",
      "106155    [1, 39, 40, 41, 42, 43, 16, 44, 9857, 45, 44, ...\n",
      "68713     [1, 56, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65...\n",
      "Name: english_sentence, dtype: object\n",
      "59399     [1, 223, 11335, 42, 816, 5606, 5487, 714, 265,...\n",
      "17253     [1, 510, 2176, 4291, 1793, 4, 3769, 74, 11335,...\n",
      "99756                 [1, 279, 2341, 42, 4881, 523, 24, 25]\n",
      "28652     [1, 11335, 59, 396, 7453, 11335, 4832, 11335, ...\n",
      "113685    [1, 570, 105, 2770, 977, 11335, 999, 19, 570, ...\n",
      "Name: hindi_sentence, dtype: object 59399     [1, 4375, 44, 9857, 618, 63, 1748, 16, 521, 23...\n",
      "17253     [1, 633, 16, 28, 1249, 3875, 254, 44, 177, 47,...\n",
      "99756                  [1, 1730, 754, 580, 164, 20, 98, 17]\n",
      "28652       [1, 9857, 4379, 9857, 63, 1718, 4536, 9857, 17]\n",
      "113685    [1, 9857, 55, 63, 9857, 492, 336, 20, 90, 18, ...\n",
      "Name: english_sentence, dtype: object\n",
      "15224     [1, 2639, 255, 12, 117, 582, 131, 27, 723, 51,...\n",
      "57682     [1, 1748, 42, 202, 947, 82, 4532, 11335, 210, ...\n",
      "75234     [1, 4076, 1372, 7918, 19, 1542, 74, 553, 344, ...\n",
      "48380     [1, 2687, 16, 703, 265, 440, 59, 117, 159, 106...\n",
      "126243                                        [1, 1240, 25]\n",
      "Name: hindi_sentence, dtype: object 15224              [1, 520, 677, 440, 518, 18, 1138, 6, 17]\n",
      "57682     [1, 875, 63, 9857, 2899, 3615, 47, 9857, 9857,...\n",
      "75234     [1, 4339, 16, 7576, 44, 1941, 1249, 57, 3089, ...\n",
      "48380     [1, 2357, 110, 57, 90, 68, 4870, 57, 1258, 752...\n",
      "126243                                        [1, 1143, 17]\n",
      "Name: english_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the words in the sentences to their corresponding index in the vocabulary\n",
    "def create_sequences(df):\n",
    "    df['english_sentence'] = df['english_sentence'].apply(lambda sentence: [english_vocab.get(word, english_vocab[OUT_OF_VOCAB_TOKEN]) for word in sentence])\n",
    "    df['hindi_sentence'] = df['hindi_sentence'].apply(lambda sentence: [hindi_vocab.get(word, hindi_vocab[OUT_OF_VOCAB_TOKEN]) for word in sentence])\n",
    "    print(df['hindi_sentence'][:5],df['english_sentence'][:5])\n",
    "\n",
    "create_sequences(train_df)\n",
    "create_sequences(val_df)\n",
    "create_sequences(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc1031",
   "metadata": {
    "papermill": {
     "duration": 0.010073,
     "end_time": "2023-07-13T06:41:04.573986",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.563913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Creating the dataloaders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c54f88c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:04.596337Z",
     "iopub.status.busy": "2023-07-13T06:41:04.595520Z",
     "iopub.status.idle": "2023-07-13T06:41:04.605644Z",
     "shell.execute_reply": "2023-07-13T06:41:04.604791Z"
    },
    "papermill": {
     "duration": 0.023388,
     "end_time": "2023-07-13T06:41:04.607629",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.584241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    english_sequences, hindi_sequences = zip(*batch)\n",
    "    english_sequences = [torch.tensor(seq) for seq in english_sequences]\n",
    "    hindi_sequences = [torch.tensor(seq) for seq in hindi_sequences]\n",
    "    \n",
    "    # Pad sequences\n",
    "    english_sequences = pad_sequence(english_sequences, batch_first=True, padding_value=0)\n",
    "    hindi_sequences = pad_sequence(hindi_sequences, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return english_sequences, hindi_sequences\n",
    "\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.df.iloc[idx]['english_sentence']), torch.tensor(self.df.iloc[idx]['hindi_sentence'])\n",
    "\n",
    "# Define a function to create data loaders\n",
    "def create_data_loaders(train_df, val_df, test_df, batch_size=8):\n",
    "    train_loader = DataLoader(TranslationDataset(train_df), batch_size=batch_size,collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(TranslationDataset(val_df),  collate_fn=collate_fn, batch_size=batch_size)\n",
    "    test_loader = DataLoader(TranslationDataset(test_df),  collate_fn=collate_fn, batch_size=batch_size)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(train_df, val_df, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591fa4a",
   "metadata": {
    "papermill": {
     "duration": 0.009965,
     "end_time": "2023-07-13T06:41:04.627852",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.617887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Visualizing the data in the dataloaders\n",
    "\n",
    "Reduce the batch_size for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ef1365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:04.654135Z",
     "iopub.status.busy": "2023-07-13T06:41:04.653233Z",
     "iopub.status.idle": "2023-07-13T06:41:04.731015Z",
     "shell.execute_reply": "2023-07-13T06:41:04.728137Z"
    },
    "papermill": {
     "duration": 0.092587,
     "end_time": "2023-07-13T06:41:04.733109",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.640522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n",
      "tensor([   1, 1480,   16,  179, 9857,    4, 2506,   63,    4,  732, 2657,   16,\n",
      "          63, 9857, 3425,  230, 9857,  529,   63, 4102, 1186,   30,  593,  953,\n",
      "         200, 1356, 3996, 6637,    4, 1340,   44, 3429, 6638,   17])\n",
      "tensor([    1,  4681,   652,  7009,    48,  1636,    16, 11335,  4436,  2107,\n",
      "           42,  4569,   302,  1412, 11335,    42,   583, 11335,   414,  7452,\n",
      "           59,  7453,  2500,    42,  5260, 11335,    16,  2765,   414,  5744,\n",
      "         1787,   742,    24,    25,     0,     0,     0,     0,     0])\n",
      "tensor([   1, 1666,   16,    7,  521, 3611,   16,  582, 2038,   57, 2332, 1005,\n",
      "         179, 1614,  290,   57, 3560,   74, 9857,   16,    4, 9857,   16,   17,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "tensor([    1,  4875,    82,  4028,    74,  8618,   302,    82,   253, 11335,\n",
      "           16, 11335,   792,   478,   269,    25,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([   1, 1724,  101,  692,  468, 4746,   57, 1210,   20,  441,   18,    4,\n",
      "        1840,   68, 4470,   57, 1296, 3234,  451,  403,  441,   18, 6591,  254,\n",
      "         439,   57,  441,  297,  402,   17,    0,    0,    0,    0])\n",
      "tensor([    1,   444,  1578,  1385,   117,   845,   716,    31,  7412,   509,\n",
      "          117,   486,    29,  2848,     4,   159,  5416,    59, 10766,  1517,\n",
      "           16,    31,   117,   486,  5614,  3320,   302,    82,   253,   510,\n",
      "         1927,    59, 11335,   302,    82,   253,   313,    24,    25])\n",
      "tensor([  1, 169, 170, 171,  47, 172, 123, 173,  16, 174, 175,  63, 176,  10,\n",
      "        177,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0])\n",
      "tensor([  1, 202,  82, 203,  47,  82, 204,  42, 205, 206,  25,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
      "tensor([   1, 4796,  353,   44,  582, 1452,  440,  441,   17,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "tensor([   1,  845,  386, 4574,   42,  802,   51,  410,   24,   25,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "tensor([   1, 9353, 5872, 7132, 1841,   16,   57, 5731,   57, 4828, 9857,  499,\n",
      "          16,   17,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "tensor([   1,  559, 5065, 2968,  214,   59,  106, 3421,    7, 2735,  302,   42,\n",
      "        3402,  955,   25,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "tensor([   1,  913, 4179,  278,   17,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "tensor([   1,  314, 2492, 2797,   25,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n",
      "tensor([   1,  520,   57, 2362,  211, 5603, 1808,  440, 9235, 4355,   22,   17,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])\n",
      "tensor([    1,   411, 11335,   379,   692,   407,     3,     4,  1955,    51,\n",
      "          410,    24,   117,    25,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "torch.Size([8, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3860200621.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  english_sequences = [torch.tensor(seq) for seq in english_sequences]\n",
      "/tmp/ipykernel_23/3860200621.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hindi_sequences = [torch.tensor(seq) for seq in hindi_sequences]\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "print(len(data[0]),len(data[1])) # = batch_size\n",
    "src , trg = data\n",
    "for i in range(len(src)):\n",
    "        print(src[i])\n",
    "        print(trg[i])\n",
    "print(src.shape) # (batch_size,length_of_sequences)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a4951",
   "metadata": {
    "papermill": {
     "duration": 0.010589,
     "end_time": "2023-07-13T06:41:04.754237",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.743648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### This marks the end of the data preparation now we will define the seq2seq model and train it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2911c",
   "metadata": {
    "papermill": {
     "duration": 0.010558,
     "end_time": "2023-07-13T06:41:04.775230",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.764672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### First we will define the encoder, then the decoder and then combine them to define the seq2seq model. After this we will train the model and do validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01650a59",
   "metadata": {
    "papermill": {
     "duration": 0.010394,
     "end_time": "2023-07-13T06:41:04.796599",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.786205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Encoder \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085944c6",
   "metadata": {
    "papermill": {
     "duration": 0.010484,
     "end_time": "2023-07-13T06:41:04.817881",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.807397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Visualizing the embeddings. \n",
    "Reducing the embedding_dim for decent visualization. Can also use embed_example.**weight.data** to see the weight matrix of embeddings. \n",
    "\n",
    "Every word has a vector of size **embedding_dim** associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2499e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:04.841093Z",
     "iopub.status.busy": "2023-07-13T06:41:04.840148Z",
     "iopub.status.idle": "2023-07-13T06:41:04.881643Z",
     "shell.execute_reply": "2023-07-13T06:41:04.880623Z"
    },
    "papermill": {
     "duration": 0.05528,
     "end_time": "2023-07-13T06:41:04.883724",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.828444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2724,  0.2142,  0.3807,  0.4334,  0.3872, -1.1835, -1.1071, -0.1841,\n",
       "         -0.4885, -1.2278,  0.6713, -1.2627, -2.3140, -1.3045,  1.2337, -0.4339],\n",
       "        [ 0.7787, -0.3580,  0.8331, -1.0472, -1.7335, -1.0104,  0.0711,  1.5074,\n",
       "          0.5364,  1.4165, -2.0296, -1.0663, -0.8677,  1.3982,  0.4945,  1.8224],\n",
       "        [-2.1643,  0.0447,  0.4287,  0.1487,  1.5372,  0.6529,  0.4082,  0.9085,\n",
       "         -1.7071, -1.5394, -0.3037, -0.7986,  0.0235, -0.4832, -1.1046,  0.5799],\n",
       "        [ 0.7884,  0.4522, -2.5227, -0.7096,  0.4728,  1.5256, -0.3603,  1.3527,\n",
       "         -0.2150, -1.1938, -0.4472,  0.4304,  2.4004,  3.1311,  0.7262,  0.8061]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(english_vocab)\n",
    "embedding_dim=16\n",
    "embed_example = nn.Embedding(input_dim, embedding_dim)\n",
    "embed_example\n",
    "embeddings = embed_example.weight.data\n",
    "embeddings[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030a4a1c",
   "metadata": {
    "papermill": {
     "duration": 0.010443,
     "end_time": "2023-07-13T06:41:04.904913",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.894470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Visualizing how dropout functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea8283f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:04.928281Z",
     "iopub.status.busy": "2023-07-13T06:41:04.927456Z",
     "iopub.status.idle": "2023-07-13T06:41:04.982321Z",
     "shell.execute_reply": "2023-07-13T06:41:04.981426Z"
    },
    "papermill": {
     "duration": 0.070255,
     "end_time": "2023-07-13T06:41:04.986118",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.915863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9847, -0.0953, -1.3843,  ...,  1.9782,  0.2396, -1.0359],\n",
      "         [-1.3195,  0.3484, -0.0924,  ..., -0.7197, -1.6797, -2.5680],\n",
      "         [ 0.1810, -0.8129,  1.7524,  ...,  0.4445, -0.0044, -2.8132],\n",
      "         ...,\n",
      "         [ 1.0120, -0.1411, -0.4691,  ...,  1.6046, -0.4548, -1.1192],\n",
      "         [-0.1552,  0.4610,  1.7449,  ..., -0.3100,  0.5175,  0.2599],\n",
      "         [ 0.1272, -0.1848,  1.2650,  ...,  0.8262, -1.0685,  0.1285]],\n",
      "\n",
      "        [[ 0.9847, -0.0953, -1.3843,  ...,  1.9782,  0.2396, -1.0359],\n",
      "         [-0.4735,  1.8389, -0.0459,  ..., -0.8488, -1.7114, -1.8881],\n",
      "         [ 0.1810, -0.8129,  1.7524,  ...,  0.4445, -0.0044, -2.8132],\n",
      "         ...,\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922]],\n",
      "\n",
      "        [[ 0.9847, -0.0953, -1.3843,  ...,  1.9782,  0.2396, -1.0359],\n",
      "         [ 1.3387, -0.0381,  1.3680,  ...,  1.4777,  0.1885, -0.4775],\n",
      "         [ 1.3070, -0.1503,  0.6816,  ..., -1.9126, -0.6087, -0.2401],\n",
      "         ...,\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9847, -0.0953, -1.3843,  ...,  1.9782,  0.2396, -1.0359],\n",
      "         [ 1.0663, -0.4903, -0.9523,  ...,  1.5212, -0.2738,  1.0157],\n",
      "         [ 1.2381,  0.0977, -0.3101,  ..., -0.8925, -0.9642, -0.2193],\n",
      "         ...,\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922]],\n",
      "\n",
      "        [[ 0.9847, -0.0953, -1.3843,  ...,  1.9782,  0.2396, -1.0359],\n",
      "         [ 1.7062,  0.5311, -0.1530,  ..., -1.1527,  0.9851,  0.5171],\n",
      "         [ 1.9562, -0.8721,  0.5303,  ..., -1.6352, -0.8804, -0.4592],\n",
      "         ...,\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922]],\n",
      "\n",
      "        [[ 0.9847, -0.0953, -1.3843,  ...,  1.9782,  0.2396, -1.0359],\n",
      "         [-0.6955, -0.7414,  0.6344,  ...,  0.3926, -0.2275,  0.8084],\n",
      "         [ 1.5307, -0.7123, -0.8365,  ...,  0.4850, -0.3684, -0.8102],\n",
      "         ...,\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922],\n",
      "         [-1.5033,  0.1097, -0.0202,  ..., -1.4170, -0.1458, -1.1922]]],\n",
      "       grad_fn=<EmbeddingBackward0>) torch.Size([8, 34, 16])\n",
      "tensor([[[-2.1419, -0.2202,  0.0000,  ...,  0.0000,  0.9093, -0.0000],\n",
      "         [ 0.0000, -2.1650, -0.0000,  ..., -0.0972,  1.0746,  0.0000],\n",
      "         [ 0.0000,  1.6061,  1.7130,  ...,  1.4543, -0.0000, -0.0537],\n",
      "         ...,\n",
      "         [-0.4416,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2163, -0.0000, -0.3239,  ..., -0.0000,  0.1628, -0.0000],\n",
      "         [-3.2999,  0.0000, -0.3739,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.9093, -1.1014],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -1.5157,  1.7009],\n",
      "         [ 0.2828,  0.0000,  1.7130,  ...,  0.0000, -1.2478, -0.0000],\n",
      "         ...,\n",
      "         [ 1.5438,  0.0000,  0.4879,  ...,  0.0000,  2.7466, -0.9742],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.3770,  2.7466, -0.9742],\n",
      "         [ 1.5438,  0.0000,  0.4879,  ...,  1.3770,  2.7466, -0.9742]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  1.8858,  ...,  1.2664,  0.0000, -1.1014],\n",
      "         [ 0.0000, -0.3402,  1.3215,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.2527,  4.2067,  0.2602,  ...,  0.0000, -2.7640,  1.0892],\n",
      "         ...,\n",
      "         [ 1.5438,  2.1474,  0.4879,  ...,  1.3770,  2.7466, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.4879,  ...,  1.3770,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.4879,  ...,  0.0000,  2.7466, -0.9742]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.1419, -0.2202,  1.8858,  ...,  1.2664,  0.9093, -0.0000],\n",
      "         [ 2.0864,  0.6667, -0.0000,  ..., -0.0000, -0.2268, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.2898,  ..., -0.0000,  2.6898, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.3770,  0.0000, -0.9742],\n",
      "         [ 1.5438,  2.1474,  0.4879,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [ 1.5438,  2.1474,  0.0000,  ...,  1.3770,  0.0000, -0.9742]],\n",
      "\n",
      "        [[-2.1419, -0.0000,  0.0000,  ...,  0.0000,  0.9093, -1.1014],\n",
      "         [ 0.0000,  0.0000,  1.9882,  ..., -1.8713,  3.4658, -0.0000],\n",
      "         [ 0.6874, -2.7523, -0.0000,  ..., -0.2952,  0.1185, -0.4312],\n",
      "         ...,\n",
      "         [ 1.5438,  0.0000,  0.4879,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [ 1.5438,  2.1474,  0.0000,  ...,  1.3770,  0.0000, -0.9742],\n",
      "         [ 1.5438,  2.1474,  0.4879,  ...,  0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  1.8858,  ...,  1.2664,  0.9093, -0.0000],\n",
      "         [ 0.0000, -1.3032,  0.0000,  ..., -3.9619, -1.5132,  0.0000],\n",
      "         [-0.0000, -0.8368, -0.0000,  ..., -0.0000,  0.0000,  0.1873],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.3770,  0.0000, -0.9742],\n",
      "         [ 1.5438,  2.1474,  0.0000,  ...,  0.0000,  2.7466, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.3770,  0.0000, -0.9742]]],\n",
      "       grad_fn=<MulBackward0>) torch.Size([8, 34, 16])\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(english_vocab)\n",
    "embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "embedded=embedding(src)\n",
    "print(embedded,embedded.shape)\n",
    "dropout = nn.Dropout(0.5)\n",
    "embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "embedded=dropout(embedding(src))\n",
    "print(embedded,embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70441dde",
   "metadata": {
    "papermill": {
     "duration": 0.010787,
     "end_time": "2023-07-13T06:41:05.007980",
     "exception": false,
     "start_time": "2023-07-13T06:41:04.997193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Visualizing the LSTM with num_layers = 3.** \n",
    "* (hidden , cell) will have the values from all the layers stacked one over another. \n",
    "* The shape of hidden and cell will be (num_layers,batch_size,hidden_dim)\n",
    "* The input shape required by LSTM if batch_first=True is (batch_size,sequence_length,input_length).\n",
    "* In our case the batch_size = **8** , sequence_length is the **length of integer sequences**, input_length is = **embedding_dim**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c5a42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:05.031241Z",
     "iopub.status.busy": "2023-07-13T06:41:05.030919Z",
     "iopub.status.idle": "2023-07-13T06:41:05.139943Z",
     "shell.execute_reply": "2023-07-13T06:41:05.138978Z"
    },
    "papermill": {
     "duration": 0.124832,
     "end_time": "2023-07-13T06:41:05.143651",
     "exception": false,
     "start_time": "2023-07-13T06:41:05.018819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.8312e-01,  2.0265e-02, -5.4521e-01,  1.9433e-01, -6.1937e-02,\n",
      "           2.2705e-01,  1.0424e-01,  9.7161e-03],\n",
      "         [ 3.8842e-01, -7.1287e-01,  5.7275e-01,  1.8696e-01, -3.7756e-02,\n",
      "           3.1588e-01,  3.2942e-01, -1.3284e-01],\n",
      "         [ 3.2524e-01, -4.3411e-01,  5.2736e-01, -2.8123e-01, -8.7427e-02,\n",
      "           2.9250e-01,  1.4738e-01,  9.0907e-02],\n",
      "         [ 9.3383e-02, -3.5597e-01,  3.5542e-01,  2.4250e-01, -1.9000e-03,\n",
      "           9.3249e-04,  2.0033e-02,  7.9614e-02],\n",
      "         [ 1.4495e-01, -4.5507e-01,  2.6401e-01,  2.2546e-01, -2.3199e-02,\n",
      "           3.9713e-02, -2.8893e-01, -9.0405e-02],\n",
      "         [ 1.4432e-01, -4.0595e-01,  4.0517e-01,  1.2881e-01, -3.2069e-02,\n",
      "          -3.9454e-02, -3.0835e-01, -1.3270e-01],\n",
      "         [ 3.1854e-01, -5.2704e-01,  5.6235e-01,  2.9652e-01,  6.3688e-02,\n",
      "           9.9210e-02, -1.3904e-01, -2.2951e-01],\n",
      "         [ 2.5299e-01, -5.7169e-01,  5.2099e-01,  2.3155e-02,  6.7252e-03,\n",
      "           4.2182e-01,  5.3297e-02, -1.0422e-01]],\n",
      "\n",
      "        [[ 1.0409e-01, -2.6423e-01, -6.3188e-02,  2.4812e-01,  3.3793e-01,\n",
      "           6.7291e-02,  6.3530e-02, -7.2247e-02],\n",
      "         [-3.5211e-02, -1.8612e-01, -6.6995e-02,  1.6551e-01,  4.4770e-01,\n",
      "           1.6945e-01,  1.1456e-01,  6.9419e-03],\n",
      "         [ 2.4007e-02, -1.3139e-01, -8.0047e-02,  2.0048e-01,  4.5357e-01,\n",
      "           1.2518e-01,  2.0833e-01,  9.4592e-02],\n",
      "         [ 8.3346e-02, -2.2061e-01, -7.6605e-02,  2.8358e-01,  4.0875e-01,\n",
      "           7.9685e-02,  5.2590e-02, -1.4052e-02],\n",
      "         [-1.8438e-02, -2.4538e-01, -7.4716e-02,  1.0083e-01,  5.1618e-01,\n",
      "           1.5130e-01,  3.7105e-03,  3.8049e-02],\n",
      "         [-1.2742e-02, -2.0239e-01, -2.0569e-02,  1.2284e-01,  4.9092e-01,\n",
      "           1.2806e-01, -6.1203e-02, -5.1186e-02],\n",
      "         [ 8.9589e-03, -1.6712e-01, -8.2041e-02,  1.8543e-01,  4.2963e-01,\n",
      "           1.1705e-01,  1.5805e-01,  1.2369e-03],\n",
      "         [-6.8928e-02, -1.6805e-01, -2.3235e-02,  3.3538e-02,  4.8825e-01,\n",
      "           9.9453e-02,  6.9777e-02, -3.8685e-02]],\n",
      "\n",
      "        [[-1.4001e-01, -1.9031e-01,  2.4077e-02, -8.7487e-02,  1.7634e-01,\n",
      "           1.5202e-01, -1.4938e-01, -8.4240e-02],\n",
      "         [-1.1830e-01, -1.8421e-01,  3.3497e-02, -1.2196e-01,  1.4483e-01,\n",
      "           1.6140e-01, -1.5842e-01, -6.4393e-02],\n",
      "         [-1.3401e-01, -2.2275e-01,  4.0825e-02, -1.4873e-01,  1.2035e-01,\n",
      "           1.7904e-01, -1.3552e-01, -1.5067e-01],\n",
      "         [-1.5439e-01, -2.1931e-01, -3.6121e-02, -9.8943e-02,  1.3616e-01,\n",
      "           1.4591e-01, -1.8292e-01, -1.6209e-01],\n",
      "         [-1.2706e-01, -1.9180e-01,  1.7369e-02, -1.0895e-01,  1.5770e-01,\n",
      "           1.4137e-01, -1.5072e-01, -9.6821e-02],\n",
      "         [-1.2390e-01, -2.0856e-01,  3.4324e-02, -1.2685e-01,  1.5837e-01,\n",
      "           1.7369e-01, -1.1090e-01, -6.7662e-02],\n",
      "         [-1.6637e-01, -2.1506e-01,  9.2092e-03, -1.1070e-01,  1.2582e-01,\n",
      "           1.6697e-01, -1.6318e-01, -1.2501e-01],\n",
      "         [-1.1704e-01, -1.9038e-01,  4.8407e-04, -5.7653e-02,  1.6114e-01,\n",
      "           1.1939e-01, -1.5078e-01, -5.4696e-02]]], grad_fn=<StackBackward0>) torch.Size([3, 8, 8])\n",
      "tensor([[[ 4.9037e-01,  4.2222e-02, -9.8190e-01,  3.8962e-01, -3.6278e-01,\n",
      "           2.9623e-01,  3.4799e-01,  2.6065e-02],\n",
      "         [ 7.2597e-01, -1.4145e+00,  1.5113e+00,  2.1016e-01, -2.0752e-01,\n",
      "           8.5028e-01,  5.4865e-01, -2.2769e-01],\n",
      "         [ 7.4388e-01, -7.3499e-01,  1.0422e+00, -3.4802e-01, -2.9222e-01,\n",
      "           5.0087e-01,  4.4610e-01,  1.2218e-01],\n",
      "         [ 1.5825e-01, -8.8684e-01,  6.0771e-01,  4.7274e-01, -8.2172e-03,\n",
      "           6.9700e-03,  2.2823e-02,  1.8642e-01],\n",
      "         [ 2.8047e-01, -1.1547e+00,  5.4734e-01,  3.3746e-01, -7.5151e-02,\n",
      "           2.8975e-01, -3.4407e-01, -2.0040e-01],\n",
      "         [ 5.4680e-01, -7.0354e-01,  8.1802e-01,  3.9585e-01, -7.7403e-02,\n",
      "          -9.8915e-02, -4.0725e-01, -2.9434e-01],\n",
      "         [ 8.3785e-01, -7.0499e-01,  9.6565e-01,  4.6346e-01,  2.3859e-01,\n",
      "           1.6389e-01, -2.0067e-01, -5.3914e-01],\n",
      "         [ 7.3478e-01, -7.8452e-01,  1.0110e+00,  4.1111e-02,  1.4342e-02,\n",
      "           5.8729e-01,  1.4406e-01, -1.9540e-01]],\n",
      "\n",
      "        [[ 2.0151e-01, -5.4474e-01, -1.5409e-01,  4.2626e-01,  6.3543e-01,\n",
      "           1.4515e-01,  1.1364e-01, -1.5513e-01],\n",
      "         [-7.2356e-02, -3.9508e-01, -1.7111e-01,  2.7705e-01,  8.0255e-01,\n",
      "           3.0732e-01,  1.9120e-01,  1.5607e-02],\n",
      "         [ 4.9074e-02, -2.2645e-01, -1.9224e-01,  3.0301e-01,  9.1841e-01,\n",
      "           2.5389e-01,  3.4645e-01,  2.3378e-01],\n",
      "         [ 1.6384e-01, -4.3092e-01, -1.6478e-01,  4.4917e-01,  7.7661e-01,\n",
      "           1.6217e-01,  9.0865e-02, -3.1438e-02],\n",
      "         [-3.6299e-02, -4.3962e-01, -1.4202e-01,  1.6288e-01,  9.5839e-01,\n",
      "           3.3800e-01,  6.5662e-03,  8.1153e-02],\n",
      "         [-2.1118e-02, -3.5627e-01, -4.1829e-02,  1.8490e-01,  9.6296e-01,\n",
      "           2.8288e-01, -1.0028e-01, -1.3041e-01],\n",
      "         [ 1.6837e-02, -3.0692e-01, -1.8812e-01,  2.8763e-01,  8.4516e-01,\n",
      "           2.3046e-01,  2.5703e-01,  3.0297e-03],\n",
      "         [-1.6234e-01, -3.2683e-01, -4.8426e-02,  5.1959e-02,  9.1145e-01,\n",
      "           2.1648e-01,  1.2946e-01, -8.1146e-02]],\n",
      "\n",
      "        [[-3.3673e-01, -4.7381e-01,  4.6411e-02, -1.6333e-01,  3.7354e-01,\n",
      "           3.5324e-01, -3.4771e-01, -1.3577e-01],\n",
      "         [-2.5216e-01, -4.5249e-01,  6.7436e-02, -2.2089e-01,  3.0730e-01,\n",
      "           3.6965e-01, -3.4101e-01, -1.1190e-01],\n",
      "         [-2.8188e-01, -5.7103e-01,  8.4885e-02, -2.6055e-01,  2.6256e-01,\n",
      "           4.0359e-01, -3.0910e-01, -2.7098e-01],\n",
      "         [-4.5930e-01, -5.7951e-01, -6.2696e-02, -2.0156e-01,  2.5174e-01,\n",
      "           4.1150e-01, -4.4595e-01, -2.6677e-01],\n",
      "         [-2.7885e-01, -4.8422e-01,  3.5381e-02, -2.0075e-01,  3.3840e-01,\n",
      "           3.2517e-01, -3.1265e-01, -1.6845e-01],\n",
      "         [-2.8053e-01, -4.9816e-01,  7.0395e-02, -2.1919e-01,  3.7136e-01,\n",
      "           3.9127e-01, -2.3107e-01, -1.1322e-01],\n",
      "         [-3.5466e-01, -5.6096e-01,  1.9166e-02, -1.9187e-01,  2.7683e-01,\n",
      "           3.7486e-01, -3.7541e-01, -2.2174e-01],\n",
      "         [-3.4721e-01, -4.9076e-01,  8.3059e-04, -1.2200e-01,  2.8812e-01,\n",
      "           3.2702e-01, -3.3705e-01, -8.5227e-02]]], grad_fn=<StackBackward0>) torch.Size([3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(16, 8, num_layers = 3, dropout = 0.5,batch_first=True)\n",
    "outputs, (enc_hidden, enc_cell) = lstm(embedded)\n",
    "print(enc_hidden,enc_hidden.shape)\n",
    "print(enc_cell,enc_cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca355e",
   "metadata": {
    "papermill": {
     "duration": 0.011418,
     "end_time": "2023-07-13T06:41:05.167098",
     "exception": false,
     "start_time": "2023-07-13T06:41:05.155680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Formally defining the Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5570d7f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:05.192146Z",
     "iopub.status.busy": "2023-07-13T06:41:05.191790Z",
     "iopub.status.idle": "2023-07-13T06:41:06.000624Z",
     "shell.execute_reply": "2023-07-13T06:41:05.999669Z"
    },
    "papermill": {
     "duration": 0.824136,
     "end_time": "2023-07-13T06:41:06.003002",
     "exception": false,
     "start_time": "2023-07-13T06:41:05.178866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# Encoder class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        # For every word(or an integer in the input sequence) it creates a vector of size embedding_dim \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim) \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = dropout,batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        #Shape of src is (batch_size,length of padded sequence)\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #Shape of embedded is (batch_size,length of one padded sequence,embedding_dim)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        # Shape of hidden and cell both is (n_layers, batch_size, hidden_dim)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f17ef4",
   "metadata": {
    "papermill": {
     "duration": 0.012123,
     "end_time": "2023-07-13T06:41:06.027165",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.015042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a02a6c",
   "metadata": {
    "papermill": {
     "duration": 0.01115,
     "end_time": "2023-07-13T06:41:06.049626",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.038476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Expected input shape by the **DECODER**(Not the lstm in the decoder) = (batch_size)\n",
    "* The input to the decoder is converted to shape (4,1) by unsqueeze operation. \n",
    "* The Embedding and dropout is similar to the Encoder layer. See Encoder for their visualization, expected shape etc.\n",
    "* Input shape to lstm is = (batch_size,1,embedding_dim)\n",
    "* The shape of hidden and cell is = (num_layers,batch_size,hidden_dim). Basically they contain the hidden and cell state at the final time step(here time step = 1) of each layer stacked on top of each other.\n",
    "* Output only contains the values from the topmost layer and it's shape is (batch_size,1,hidden_dim)\n",
    "* The output is passed through a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36ac0bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:06.074579Z",
     "iopub.status.busy": "2023-07-13T06:41:06.073266Z",
     "iopub.status.idle": "2023-07-13T06:41:06.081600Z",
     "shell.execute_reply": "2023-07-13T06:41:06.080592Z"
    },
    "papermill": {
     "duration": 0.023158,
     "end_time": "2023-07-13T06:41:06.083948",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.060790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decoder class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout = dropout, batch_first=True )\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8ae58",
   "metadata": {
    "papermill": {
     "duration": 0.011002,
     "end_time": "2023-07-13T06:41:06.106584",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.095582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Trying out the decoder and checking the output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c4475d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:06.130724Z",
     "iopub.status.busy": "2023-07-13T06:41:06.130374Z",
     "iopub.status.idle": "2023-07-13T06:41:06.154917Z",
     "shell.execute_reply": "2023-07-13T06:41:06.153835Z"
    },
    "papermill": {
     "duration": 0.03902,
     "end_time": "2023-07-13T06:41:06.157108",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.118088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 11336]) torch.Size([3, 8, 8]) torch.Size([3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "output_dim=len(hindi_vocab)\n",
    "input=trg[:,1]\n",
    "decoder=Decoder(output_dim,16,8,3,0.5)\n",
    "output, hidden, cell = decoder(input, enc_hidden, enc_cell)\n",
    "print(output.shape,hidden.shape,cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af308e96",
   "metadata": {
    "papermill": {
     "duration": 0.011398,
     "end_time": "2023-07-13T06:41:06.180058",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.168660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### The Seq2Seq Class\n",
    "* This basically takes the input in the training loop. Feeds to the encoder, gets the output, then feeds the context vector(final hidden and cell state of encoder for each layer) to the decoder and generates output by calling the decoder one word at a time, clubs it together and returns the output in the desired shape.\n",
    "* Our decoder generates the output one word after another.\n",
    "* We initially feed the decoder with the SOS token.\n",
    "* Teacher_Forcing_Ratio : The next input to the decoder could be a word from the target sentence or the prediction generated in the previous step by the decoder. It is decided by teacher_forcing_ratio. For example if teacher forcing ratio is 0.6 or 60% then for 60% of the time input will be the original word.\n",
    "* The output shape is: (length of a target sequence, batch_size, output_dim)\n",
    "* Also setting the device for orders of magnitude faster performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "617152bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:06.204725Z",
     "iopub.status.busy": "2023-07-13T06:41:06.204040Z",
     "iopub.status.idle": "2023-07-13T06:41:06.212881Z",
     "shell.execute_reply": "2023-07-13T06:41:06.211788Z"
    },
    "papermill": {
     "duration": 0.02403,
     "end_time": "2023-07-13T06:41:06.215418",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.191388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seq2Seq class\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = target.shape[0]\n",
    "        trg_len = target.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(source)\n",
    "        input = target[:,0]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1) \n",
    "            input = target[:,t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a0a1bd",
   "metadata": {
    "papermill": {
     "duration": 0.011214,
     "end_time": "2023-07-13T06:41:06.238020",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.226806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training the model and calculating validation\n",
    "\n",
    "* Defining the hyperparameters and setting the device.\n",
    "* Initializing the encoder,decoder and model. Initializing the loss function and optimizer.\n",
    "* Shape of output and target before modification = (len(target), batch_size, output_dim) and (batch_size,len(target)) respectively.\n",
    "* Shape of output and target after modification = ((len(target)-1)\\*batch_size, output_dim) and (batch_size\\*(len(target)-1)) respectively. This is consistent with the shapes expected by the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc811a17",
   "metadata": {
    "papermill": {
     "duration": 0.011007,
     "end_time": "2023-07-13T06:41:06.260266",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.249259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function initializes all the weights of the model from a uniform distribution of (-0.08, 0.08), same as mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1572e8c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:06.284516Z",
     "iopub.status.busy": "2023-07-13T06:41:06.284120Z",
     "iopub.status.idle": "2023-07-13T06:41:06.290112Z",
     "shell.execute_reply": "2023-07-13T06:41:06.289199Z"
    },
    "papermill": {
     "duration": 0.020588,
     "end_time": "2023-07-13T06:41:06.292199",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.271611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f96ae072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T06:41:06.317716Z",
     "iopub.status.busy": "2023-07-13T06:41:06.317352Z",
     "iopub.status.idle": "2023-07-13T07:00:32.528863Z",
     "shell.execute_reply": "2023-07-13T07:00:32.524648Z"
    },
    "papermill": {
     "duration": 1166.237321,
     "end_time": "2023-07-13T07:00:32.541077",
     "exception": false,
     "start_time": "2023-07-13T06:41:06.303756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3860200621.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  english_sequences = [torch.tensor(seq) for seq in english_sequences]\n",
      "/tmp/ipykernel_23/3860200621.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hindi_sequences = [torch.tensor(seq) for seq in hindi_sequences]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after Epoch = 0 is: 3.924301615628329\n",
      "validation loss after Epoch = 0 is: 3.6940734579868635\n",
      "Training loss after Epoch = 1 is: 3.806098015928717\n",
      "validation loss after Epoch = 1 is: 3.668039105479764\n",
      "Training loss after Epoch = 2 is: 3.7832354318385586\n",
      "validation loss after Epoch = 2 is: 3.657054498003054\n",
      "Training loss after Epoch = 3 is: 3.7843941264017995\n",
      "validation loss after Epoch = 3 is: 3.643420433018533\n",
      "Training loss after Epoch = 4 is: 3.7616198863355343\n",
      "validation loss after Epoch = 4 is: 3.6382779989567973\n",
      "Training loss after Epoch = 5 is: 3.7324353487887727\n",
      "validation loss after Epoch = 5 is: 3.6374386232709486\n",
      "Training loss after Epoch = 6 is: 3.7517867027778986\n",
      "validation loss after Epoch = 6 is: 3.6417413399578136\n",
      "Training loss after Epoch = 7 is: 3.744742383852274\n",
      "validation loss after Epoch = 7 is: 3.6342693445244207\n",
      "Training loss after Epoch = 8 is: 3.741188090273579\n",
      "validation loss after Epoch = 8 is: 3.6369617019357126\n",
      "Training loss after Epoch = 9 is: 3.746049014826927\n",
      "validation loss after Epoch = 9 is: 3.628045406846283\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = len(english_vocab)\n",
    "output_dim=len(hindi_vocab)\n",
    "enc_embedding_dim = dec_embedding_dim = 32\n",
    "hidden_dim = 32\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "num_epochs=10\n",
    "\n",
    "# Initialize encoder, decoder and seq2seq model\n",
    "encoder = Encoder(input_dim, enc_embedding_dim, hidden_dim, n_layers, dropout)\n",
    "decoder = Decoder(output_dim, dec_embedding_dim, hidden_dim, n_layers, dropout)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model.apply(init_weights)\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr=0.01\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "least_loss=float('inf')\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss=0\n",
    "    n=len(train_loader)\n",
    "    s=time.time()\n",
    "    #print(f\"Training for Epoch={epoch} starting....\")\n",
    "    for i, (src, trg) in enumerate(train_loader):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[:,1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()\n",
    "        #print(f\"Training batch {i} out of {n} time elapsed = {time.time()-s} seconds\")\n",
    "\n",
    "    print(f\"Training loss after Epoch = {epoch} is:\" ,train_loss/len(train_loader)) \n",
    "        \n",
    "    #print(f\"Validation for Epoch={epoch} starting....\")\n",
    "    s=time.time()\n",
    "    # Validation\n",
    "    val_loss=0\n",
    "    n=len(val_loader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg) in enumerate(val_loader):\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg,0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[:,1:].reshape(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            val_loss+=loss.item()     \n",
    "            #print(f\"Validation batch {i} out of {n} time elapsed = {time.time()-s} seconds\")\n",
    "        if val_loss<least_loss:\n",
    "            least_loss=val_loss\n",
    "            best_model=model\n",
    "    print(f\"validation loss after Epoch = {epoch} is:\" ,val_loss/len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4712af7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T07:00:32.569550Z",
     "iopub.status.busy": "2023-07-13T07:00:32.569250Z",
     "iopub.status.idle": "2023-07-13T07:00:32.583000Z",
     "shell.execute_reply": "2023-07-13T07:00:32.582159Z"
    },
    "papermill": {
     "duration": 0.02941,
     "end_time": "2023-07-13T07:00:32.584997",
     "exception": false,
     "start_time": "2023-07-13T07:00:32.555587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1193.312861,
   "end_time": "2023-07-13T07:00:35.022367",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-13T06:40:41.709506",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
